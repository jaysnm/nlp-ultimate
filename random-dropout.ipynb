{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 training samples\n",
      "10000 testing samples\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.3588 - acc: 0.8978 - mae: 0.0364 - val_loss: 0.1735 - val_acc: 0.9516 - val_mae: 0.0175\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.1412 - acc: 0.9582 - mae: 0.0147 - val_loss: 0.1329 - val_acc: 0.9605 - val_mae: 0.0132\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.0989 - acc: 0.9703 - mae: 0.0105 - val_loss: 0.1037 - val_acc: 0.9693 - val_mae: 0.0097\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0733 - acc: 0.9783 - mae: 0.0079 - val_loss: 0.1001 - val_acc: 0.9700 - val_mae: 0.0089\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.0573 - acc: 0.9823 - mae: 0.0064 - val_loss: 0.1007 - val_acc: 0.9698 - val_mae: 0.0086\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.0448 - acc: 0.9865 - mae: 0.0052 - val_loss: 0.0875 - val_acc: 0.9753 - val_mae: 0.0069\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.0364 - acc: 0.9886 - mae: 0.0043 - val_loss: 0.0884 - val_acc: 0.9749 - val_mae: 0.0067\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.0279 - acc: 0.9916 - mae: 0.0034 - val_loss: 0.0931 - val_acc: 0.9742 - val_mae: 0.0067\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.0238 - acc: 0.9921 - mae: 0.0030 - val_loss: 0.0920 - val_acc: 0.9753 - val_mae: 0.0061\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.0201 - acc: 0.9938 - mae: 0.0025 - val_loss: 0.0977 - val_acc: 0.9747 - val_mae: 0.0063\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.0177 - acc: 0.9946 - mae: 0.0022 - val_loss: 0.1023 - val_acc: 0.9733 - val_mae: 0.0063\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.0133 - acc: 0.9960 - mae: 0.0017 - val_loss: 0.0936 - val_acc: 0.9762 - val_mae: 0.0056\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.0099 - acc: 0.9970 - mae: 0.0014 - val_loss: 0.1063 - val_acc: 0.9753 - val_mae: 0.0057\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.0128 - acc: 0.9959 - mae: 0.0016 - val_loss: 0.1119 - val_acc: 0.9737 - val_mae: 0.0060\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.0125 - acc: 0.9961 - mae: 0.0015 - val_loss: 0.1066 - val_acc: 0.9742 - val_mae: 0.0058\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.0087 - acc: 0.9974 - mae: 0.0011 - val_loss: 0.1008 - val_acc: 0.9763 - val_mae: 0.0052\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0069 - acc: 0.9976 - mae: 9.4578e-04 - val_loss: 0.1106 - val_acc: 0.9768 - val_mae: 0.0050\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 2s 31us/step - loss: 0.0093 - acc: 0.9970 - mae: 0.0011 - val_loss: 0.1054 - val_acc: 0.9787 - val_mae: 0.0050\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.0088 - acc: 0.9974 - mae: 0.0010 - val_loss: 0.1187 - val_acc: 0.9766 - val_mae: 0.0052\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.0109 - acc: 0.9962 - mae: 0.0012 - val_loss: 0.1131 - val_acc: 0.9753 - val_mae: 0.0053\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0055 - acc: 0.9984 - mae: 7.1216e-04 - val_loss: 0.1294 - val_acc: 0.9753 - val_mae: 0.0054\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0081 - acc: 0.9969 - mae: 9.6044e-04 - val_loss: 0.1229 - val_acc: 0.9769 - val_mae: 0.0051\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0045 - acc: 0.9987 - mae: 5.8611e-04 - val_loss: 0.1234 - val_acc: 0.9772 - val_mae: 0.0050\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0040 - acc: 0.9987 - mae: 5.0195e-04 - val_loss: 0.1297 - val_acc: 0.9773 - val_mae: 0.0049\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0058 - acc: 0.9982 - mae: 6.6540e-04 - val_loss: 0.1370 - val_acc: 0.9757 - val_mae: 0.0050\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0071 - acc: 0.9979 - mae: 7.4915e-04 - val_loss: 0.1382 - val_acc: 0.9752 - val_mae: 0.0052\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0069 - acc: 0.9977 - mae: 7.5422e-04 - val_loss: 0.1347 - val_acc: 0.9755 - val_mae: 0.0052\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.0074 - acc: 0.9973 - mae: 7.9242e-04 - val_loss: 0.1304 - val_acc: 0.9762 - val_mae: 0.0051\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0038 - acc: 0.9987 - mae: 4.6436e-04 - val_loss: 0.1280 - val_acc: 0.9774 - val_mae: 0.0048\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 9.0488e-04 - acc: 0.9998 - mae: 1.4572e-04 - val_loss: 0.1164 - val_acc: 0.9795 - val_mae: 0.0043\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 2.3142e-04 - acc: 1.0000 - mae: 4.3029e-05 - val_loss: 0.1179 - val_acc: 0.9797 - val_mae: 0.0042\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 9.1163e-05 - acc: 1.0000 - mae: 1.8162e-05 - val_loss: 0.1185 - val_acc: 0.9800 - val_mae: 0.0042\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 6.8866e-05 - acc: 1.0000 - mae: 1.3742e-05 - val_loss: 0.1196 - val_acc: 0.9801 - val_mae: 0.0042\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 5.5715e-05 - acc: 1.0000 - mae: 1.1125e-05 - val_loss: 0.1212 - val_acc: 0.9798 - val_mae: 0.0042\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 4.7705e-05 - acc: 1.0000 - mae: 9.5279e-06 - val_loss: 0.1224 - val_acc: 0.9799 - val_mae: 0.0041\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 4.1056e-05 - acc: 1.0000 - mae: 8.2016e-06 - val_loss: 0.1235 - val_acc: 0.9799 - val_mae: 0.0041\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 3.5124e-05 - acc: 1.0000 - mae: 7.0182e-06 - val_loss: 0.1245 - val_acc: 0.9801 - val_mae: 0.0041\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 3.0775e-05 - acc: 1.0000 - mae: 6.1499e-06 - val_loss: 0.1256 - val_acc: 0.9803 - val_mae: 0.0041\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 2.6915e-05 - acc: 1.0000 - mae: 5.3793e-06 - val_loss: 0.1272 - val_acc: 0.9801 - val_mae: 0.0041\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 2.3138e-05 - acc: 1.0000 - mae: 4.6248e-06 - val_loss: 0.1281 - val_acc: 0.9803 - val_mae: 0.0041\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 2.0639e-05 - acc: 1.0000 - mae: 4.1249e-06 - val_loss: 0.1300 - val_acc: 0.9800 - val_mae: 0.0041\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 1.7613e-05 - acc: 1.0000 - mae: 3.5212e-06 - val_loss: 0.1308 - val_acc: 0.9801 - val_mae: 0.0041\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 1.5198e-05 - acc: 1.0000 - mae: 3.0386e-06 - val_loss: 0.1317 - val_acc: 0.9806 - val_mae: 0.0040\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 1.3223e-05 - acc: 1.0000 - mae: 2.6438e-06 - val_loss: 0.1329 - val_acc: 0.9805 - val_mae: 0.0040\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 1.1447e-05 - acc: 1.0000 - mae: 2.2889e-06 - val_loss: 0.1346 - val_acc: 0.9805 - val_mae: 0.0040\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 9.6796e-06 - acc: 1.0000 - mae: 1.9357e-06 - val_loss: 0.1362 - val_acc: 0.9809 - val_mae: 0.0040\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 8.7028e-06 - acc: 1.0000 - mae: 1.7403e-06 - val_loss: 0.1366 - val_acc: 0.9812 - val_mae: 0.0039\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 7.4124e-06 - acc: 1.0000 - mae: 1.4824e-06 - val_loss: 0.1400 - val_acc: 0.9806 - val_mae: 0.0040\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0360 - acc: 0.9910 - mae: 0.0021 - val_loss: 0.1349 - val_acc: 0.9750 - val_mae: 0.0055\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.0105 - acc: 0.9967 - mae: 9.9731e-04 - val_loss: 0.1358 - val_acc: 0.9760 - val_mae: 0.0051\n",
      "10000/10000 [==============================] - 0s 19us/step\n",
      "Test score 0.12056878342835058\n",
      "Test accuracy 0.9768999814987183\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "np.random.seed(1671)\n",
    "epochs=50\n",
    "batch_size=128\n",
    "verbose=1\n",
    "nb_classes=10\n",
    "n_hidden=128\n",
    "validation_split=0.2\n",
    "reshaped=784\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "x_train=x_train.reshape(60000,reshaped)\n",
    "x_test=x_test.reshape(10000,reshaped)\n",
    "x_train=x_train.astype('float32')\n",
    "x_test=x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('{} training samples'.format(x_train.shape[0]))\n",
    "print('{} testing samples'.format(x_test.shape[0]))\n",
    "y_train=np_utils.to_categorical(y_train,nb_classes)\n",
    "y_test=np_utils.to_categorical(y_test,nb_classes)\n",
    "model=Sequential()\n",
    "model.add(Dense(n_hidden,input_shape=(reshaped,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['acc','mae'])\n",
    "history=model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=verbose,validation_split=validation_split)\n",
    "score=model.evaluate(x_test,y_test)\n",
    "print('Test score {}'.format(score[0]))\n",
    "print('Test accuracy {}'.format(score[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
