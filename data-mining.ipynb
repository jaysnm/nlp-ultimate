{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook covers  \n",
    "1. Operations with strings\n",
    "2. Pattern matching with regular expressions\n",
    "3. Web scrapping (requests, urllib, Beautiful Soup)\n",
    "4. Data Serialization (simplejson and pickle)\n",
    "5. Input/Output (file-systems and database systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. [Operations with Strings](https://docs.python.org/3/library/string.html)   \n",
    "\n",
    "A string is a sequence of characters. \n",
    "All the string methods always return new values and do not change or manipulate the original string.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"\n",
    "A string is a sequence of characters. \n",
    "All the string Methods always return NEW values and do not change or manipulate the original string.\n",
    "\"\"\"\n",
    "word='characters'\n",
    "\n",
    "print(word.center(50,'.'))\n",
    "print(\"Occurences of word 'string' in the text : {}\".format(text.count('string')))\n",
    "print(\"First instance (index) of word 'string' in the text: {}\".format(text.find('string')))\n",
    "print('text swapped cases: {}'.format(text.swapcase()))\n",
    "print('Capitalize every first letter of words in text: {}'.format(text.title()))\n",
    "print('***... Sentence ..$%\\n'.strip('*.%$'))\n",
    "print(\"another sentence\\n\".zfill(50))\n",
    "print('***... Sentence ..$%'+' another sentence\\n')\n",
    "print(text[text.index('string',15):text.find('the',text.index('string',15))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other string methods include: \n",
    "- capitalize( ) - capitalizes only the first character of a string.  \n",
    "- upper() - capitalizes all the letters of the string.  \n",
    "- split() - returns a list of words in a string where default separator is any whitespace.  \n",
    "- startswith() - returns True if the string starts with the specified value; otherwise, it returns False.  \n",
    "- endswith() - returns True if the string endswith the specified value, else it returns False.  \n",
    "- ljust() - returns a left-justified version of the given string using a specified character, whitespace being default.   \n",
    "- rjust() - aligns the string to the right.  \n",
    "- strip() - returns a copy of the string with the leading and trailing characters removed. Default character to be removed is whitespace.  \n",
    "- zfill() - adds zeros(0) at the beginning of the string. The length of the returned string depends on the width provided.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pattern matching with [regular expressions](https://docs.python.org/3/howto/regex.html)  \n",
    "\n",
    "A regular expression is a special sequence of characters that helps you match or find other strings or sets of strings, using a specialized syntax held in a pattern.  \n",
    "There are various characters, which would have special meaning when they are used in regular expression. To avoid any confusion while dealing with regular expressions, we would use Raw Strings as **r'expression'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "t = re.match(r'text','text123')\n",
    "print(t.group(),t.span())\n",
    "\n",
    "s= re.search(r'text','.... 08text98.....')\n",
    "print(s.group(),s.span())\n",
    "\n",
    "n = re.search(r'\\W+','8773 .... text 11 test 254')\n",
    "print(n.group(),n.span())\n",
    "\n",
    "p = re.compile(r'\\d+')\n",
    "p.findall('12 drummers drumming, 11 pipers piping, 10 lords a-leaping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"Cats are smarter than dogs\"\n",
    "\n",
    "matchObj = re.match( r'(.*) are (.*?) .*', line, re.M|re.I)\n",
    "\n",
    "if matchObj:\n",
    "   print (\"matchObj.group() : \", matchObj.group())\n",
    "   print (\"matchObj.group(1) : \", matchObj.group(1))\n",
    "   print (\"matchObj.group(2) : \", matchObj.group(2))\n",
    "else:\n",
    "   print (\"No match!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchObj = re.search( r'(.*) are (.*?) .*', line, re.M|re.I)\n",
    "\n",
    "if searchObj:\n",
    "   print (\"searchObj.group() : \", searchObj.group())\n",
    "   print (\"searchObj.group(1) : \", searchObj.group(1))\n",
    "   print (\"searchObj.group(2) : \", searchObj.group(2))\n",
    "else:\n",
    "   print (\"Nothing found!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchObj = re.match( r'dogs', line, re.M|re.I)\n",
    "if matchObj:\n",
    "   print (\"match --> matchObj.group() : \", matchObj.group())\n",
    "else:\n",
    "   print (\"No match!!\")\n",
    "\n",
    "searchObj = re.search( r'dogs', line, re.M|re.I)\n",
    "if searchObj:\n",
    "   print (\"search --> searchObj.group() : \", searchObj.group())\n",
    "else:\n",
    "   print (\"Nothing found!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search and Replace\n",
    "phone = \"2004-959-559 # This is Phone Number\"\n",
    "\n",
    "# Delete Python-style comments\n",
    "num = re.sub(r'#.*$', \"\", phone)\n",
    "print (\"Phone Num : \", num)\n",
    "\n",
    "# Remove anything other than digits\n",
    "num = re.sub(r'\\D', \"\", phone)    \n",
    "print (\"Phone Num : \", num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Web Scrapping (Data Mining)\n",
    "\n",
    "### requests module  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "events = requests.get('https://api.github.com/events')\n",
    "events.json()[0]['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = requests.get('https://reqres.in/api/users?page=2')\n",
    "users.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user={\n",
    "    \"name\": \"test254\",\n",
    "    \"job\": \"developer\"\n",
    "}\n",
    "req = requests.post('https://reqres.in/api/users',data=user)\n",
    "print(req.status_code,'\\n',req.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [urllib](https://docs.python.org/3/howto/urllib2.html) module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "req= request.urlopen('https://www.entrepreneur.com/article/240492')\n",
    "req.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = request.urlopen('https://www.lifehack.org/articles/communication/10-famous-failures-that-will-inspire-you-success.html')\n",
    "strory.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request with headers \n",
    "headers ={\n",
    "    \"method\":\"GET\",\n",
    "    \"accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\",\n",
    "    \"cookie\":\"crfgL0cSt0r=true; __cfduid=d6c34bb6be1b99a723a8ad3cd2bb8b98c1569933817; cf_2355_id=b00e0659-ea5c-4f36-a24f-fbc7f24c50d7; cf_2355_cta_33455=44861; cf_2355_cta_33454=44863; cf_2355_cta_33338=44864; cf_2355_cta_33456=44867; cf_2355_cta_33463=44858; cf_2355_cta_33048=44802; cf_2355_cta_32649=44868; cf_2355_cta_27270=44806; cf_2355_cta_27306=44807; cf_2355_cta_30789=44809; cf_2355_cta_31153=44342; cf_2355_cta_28512=44078; cf_2355_cta_29689=44799; cf_2355_cta_18329=22701; cf_2355_cta_18686=undefined; cf_2355_cta_18637=34458; cf_2355_cta_19039=37195; cf_2355_cta_27671=44559; cf_2355_cta_28869=undefined; cf_2355_cta_29181=39318; cf_2355_cta_30191=41129; cf_2355_cta_30858=39180; cf_2355_cta_31888=40543; cf_2355_cta_33654=42927; cf_2355_cta_33856=43205; cf_2355_cta_33921=43290; cf_2355_cta_34002=43416; cf_2355_cta_34007=44795; cf_2355_cta_35057=45000; gdpr=consented; euconsent=BOnwOQYOnwOmMAAAAAAACa-AAAAo1rv___7__9_-____9uz7Ov_v_f__33e87_9v_h_7_-___u_-3zd4u_1vf99yfm1-7ctr3tp_87uesm_Xur__59__3z3_9phPr8k89r6337EwwEA; consentId=afbd44ce-7565-49ae-a3a5-8dd571b53b5b; pgsrc=pghb.lifehack.article.js; ac_enable_tracking=1; _ga=GA1.2.1760954512.1569933967; _gid=GA1.2.2017657937.1569933967; _fbp=fb.1.1569933967396.1686572414; _hjid=45bf0821-e9e3-4d65-a416-a16ec3d68baf; m2session=a39c11ad-7e05-482a-bb69-bdd8bac1b649; session_depth=1; m2hb=enabled; df_active=true; __gads=ID=fb106cd0e6bc8b9d:T=1569933976:S=ALNI_MaGbDrifNKtkrOQ4_Z1HqYwGPSvJA; cf_2355_person_time=1569933978471\",\n",
    "    \"User-Agent\":\"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.27 Safari/537.17\"\n",
    "}\n",
    "story = request.urlopen('https://www.lifehack.org/articles/communication/10-famous-failures-that-will-inspire-you-success.html')\n",
    "strory.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "req=requests.get('https://www.lifehack.org/articles/communication/10-famous-failures-that-will-inspire-you-success.html')\n",
    "req.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [beautiful soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-beautiful-soup)  \n",
    "\n",
    "Beautiful Soup is a Python library for pulling data out of HTML and XML files. \n",
    "Web scraping refer to automatic extraction data and presentation of it in a format a human can easily make sense of. Web scraping can be used in a wide variety of situations.  \n",
    "\n",
    "#### Scraping Rules\n",
    "1. You should check a websiteâ€™s Terms and Conditions before you scrape it. Be careful to read the statements about legal use of data. Usually, the data you scrape should not be used for commercial purposes.\n",
    "2. Do not request data from the website too aggressively with your program (also known as spamming), as this may break the website. Make sure your program behaves in a reasonable manner (i.e. acts like a human). One request for one webpage per second is good practice.\n",
    "3. The layout of a website may change from time to time, so make sure to revisit the site and rewrite your code as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "# get page content, use requests module in place of urllib for better experience\n",
    "page =  urllib.request.urlopen('https://americanliterature.com/100-great-short-stories')\n",
    "# parse the html using beautiful soup and store in variable `soup`\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "page = requests.get('https://www.thestorycorner.org/blogs/news')\n",
    "soup = BeautifulSoup(page.text,'html.parser')\n",
    "article_info = soup.find('div', attrs={'class': 'article-info-inner'})\n",
    "print(article_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(article_info.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body=soup.find('body')\n",
    "print(body.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "for link in soup.find_all('a'):\n",
    "    links.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Serialization   \n",
    "\n",
    "### [simplejson](https://simplejson.readthedocs.io/en/latest/)   \n",
    "\n",
    "simplejson is a simple, fast, complete, correct and extensible [JSON](http://json.org/) encoder and decoder. \n",
    "> The encoder can be specialized to provide serialization in any kind of situation, without any special support by the objects to be serialized (somewhat like pickle). This is best done with the default kwarg to dumps.  \n",
    "The decoder can handle incoming JSON strings of any specified encoding (UTF-8 by default).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplejson as json\n",
    "\n",
    "data={'3': 5, '1': 7,'fruits':['passion', 'strawberry', 'mangoe','plum']}\n",
    "\n",
    "print(json.dumps(data, sort_keys=True, indent=4 * ' '))\n",
    "\n",
    "with open('json_data.json','w') as json_in:\n",
    "    json.dump(data,json_in)\n",
    "    \n",
    "with open('json_data.json','r') as json_out:\n",
    "    json_data=json.load(json_out)\n",
    "    \n",
    "print('JSON data: {}'.format(json_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [pickle](https://docs.python.org/3/library/pickle.html)   \n",
    "\n",
    "Pickling (serialization with pickle) is the act of translating python data objects into a format that can be transferred from RAM to disk. pickled Python objects can be easily unpickled back to their original form (deserialisation).  \n",
    "Although JSON format is human-readable, language-independent, and faster than pickle, only a limited subset of Python built-in types can be represented by JSON. With Pickle, we can easily serialize a very large spectrum of Python types, and, importantly, custom classes. This means we don't need to create a custom schema (like we do for JSON) and write error-prone serializers and parsers. All of the heavy liftings is done for you with Pickle.  \n",
    "\n",
    "#### What can be Pickled and Unpickled\n",
    "- All native datatypes supported by Python (booleans, None, integers, floats, complex numbers, strings, bytes, byte arrays)\n",
    "- Dictionaries, sets, lists, and tuples - as long as they contain pickleable objects\n",
    "- Functions and classes that are defined at the top level of a module  \n",
    "\n",
    "> It is important to noter that pickling is not a language-independent serialization method, therefore your pickled data can only be unpickled using Python. Moreover, it's important to make sure that objects are pickled using the same version of Python that is going to be used to unpickle them. Mixing Python versions, in this case, can cause many problems.  \n",
    "Additionally, functions are pickled by their name references, and not by their value. The resulting pickle does not contain information on the function's code or attributes. Therefore, you have to make sure that the environment where the function is unpickled is able to import the function. In other words, if we pickle a function and then unpickle it in an environment where it's either not defined or not imported, an exception will be raised.  \n",
    "#### It is also very important to note that pickled objects can be used in malevolent ways. For instance, unpickling data from an untrusted source can result in the execution of a malicious piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling (serializing)\n",
    "\n",
    "import pickle\n",
    "\n",
    "fruits = ['passion', 'strawberry', 'mangoe','plum']\n",
    "\n",
    "with open('fruits_pickle.pkl', 'wb') as pickle_out:\n",
    "    pickle.dump(fruits, pickle_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpickling (deserialization)\n",
    "\n",
    "with open('fruits_pickle.pkl', 'rb') as pickle_in:\n",
    "    unpickled_data = pickle.load(pickle_in)\n",
    "\n",
    "print(unpickled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Pickling and Unpickling Custom Objects\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self):\n",
    "        self.activated = False\n",
    "    def activate(self):\n",
    "        self.activated = True\n",
    "    def set_traing_data(self,data):\n",
    "        self.traing_data=data\n",
    "    \n",
    "\n",
    "model = NeuralNetwork()\n",
    "model.activate()\n",
    "model.traing_data=unpickled_data\n",
    "\n",
    "with open('object_pickle', 'wb') as pickle_out:\n",
    "    pickle.dump(model, pickle_out)\n",
    "\n",
    "with open('object_pickle', 'rb') as pickle_in:\n",
    "    unpickled_object = pickle.load(pickle_in)\n",
    "\n",
    "print('Activated: {} \\nTraining Data: {}'.format(unpickled_object.activated,unpickled_object.traing_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember, that we can only unpickle the object in an environment where the class NeuralNetwork is either defined or imported. If we create a new script and try to unpickle the object without importing the NeuralNetwork class, we'll get an \"AttributeError\".**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Input and Output (IO)  \n",
    "\n",
    "### [csv file](https://docs.python.org/3/library/csv.html)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simplejson import loads,dumps\n",
    "import csv\n",
    "\n",
    "with open('Highway1.csv','r') as csvfile:\n",
    "    data_list=csv.reader(csvfile,delimiter=',')\n",
    "    for row in data_list:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Highway1.csv','r') as csvfile:\n",
    "    data_dict=csv.DictReader(csvfile,delimiter=',')\n",
    "    for row in data_dict:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('json_data.json','r') as jsonfile:\n",
    "    data=loads(jsonfile.read())\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "\n",
    "request = get('https://api.github.com/events')\n",
    "data = request.json()\n",
    "fieldnames=list(data[0].keys())\n",
    "\n",
    "with open('github_events_data.csv','w') as csvfile:\n",
    "    writer=csv.DictWriter(csvfile,fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    try:\n",
    "        writer.writerows(data)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "with open('github_events_data.json','w') as jsonfile:\n",
    "    jsonfile.write(dumps(data))\n",
    "    \n",
    "with open('github_events_data.json') as jsonfile:\n",
    "    print(loads(jsonfile.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [excel files](http://www.python-excel.org/)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing to excel using [xlsxwriter](https://xlsxwriter.readthedocs.io/)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "# Create a workbook and add a worksheet.\n",
    "workbook = xlsxwriter.Workbook('Expenses.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "# Some data we want to write to the worksheet.\n",
    "expenses = (\n",
    "    ['Rent', 1000],\n",
    "    ['Gas',   100],\n",
    "    ['Food',  300],\n",
    "    ['Gym',    50],\n",
    ")\n",
    "\n",
    "# Start from the first cell. Rows and columns are zero indexed.\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "# Iterate over the data and write it out row by row.\n",
    "for item, cost in (expenses):\n",
    "    worksheet.write(row, col,     item)\n",
    "    worksheet.write(row, col + 1, cost)\n",
    "    row += 1\n",
    "\n",
    "# Write a total using a formula.\n",
    "worksheet.write(row, 0, 'Total')\n",
    "worksheet.write(row, 1, '=SUM(B1:B4)')\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import xlsxwriter\n",
    "\n",
    "# Create a workbook and add a worksheet.\n",
    "workbook = xlsxwriter.Workbook('Expenses-mixed.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "# Add a bold format to use to highlight cells.\n",
    "bold = workbook.add_format({'bold': 1})\n",
    "\n",
    "# Add a number format for cells with money.\n",
    "money_format = workbook.add_format({'num_format': '$#,##0'})\n",
    "\n",
    "# Add an Excel date format.\n",
    "date_format = workbook.add_format({'num_format': 'mmmm d yyyy'})\n",
    "\n",
    "# Adjust the column width.\n",
    "worksheet.set_column(1, 1, 15)\n",
    "\n",
    "# Write some data headers.\n",
    "worksheet.write('A1', 'Item', bold)\n",
    "worksheet.write('B1', 'Date', bold)\n",
    "worksheet.write('C1', 'Cost', bold)\n",
    "\n",
    "# Some data we want to write to the worksheet.\n",
    "expenses = (\n",
    " ['Rent', '2013-01-13', 1000],\n",
    " ['Gas',  '2013-01-14',  100],\n",
    " ['Food', '2013-01-16',  300],\n",
    " ['Gym',  '2013-01-20',   50],\n",
    ")\n",
    "\n",
    "# Start from the first cell below the headers.\n",
    "row = 1\n",
    "col = 0\n",
    "\n",
    "for item, date_str, cost in (expenses):\n",
    "    # Convert the date string into a datetime object.\n",
    "    date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "\n",
    "    worksheet.write_string  (row, col,     item              )\n",
    "    worksheet.write_datetime(row, col + 1, date, date_format )\n",
    "    worksheet.write_number  (row, col + 2, cost, money_format)\n",
    "    row += 1\n",
    "\n",
    "# Write a total using a formula.\n",
    "worksheet.write(row, 0, 'Total', bold)\n",
    "worksheet.write(row, 2, '=SUM(C2:C5)', money_format)\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing to and reading from excel using [openpyxl](https://openpyxl.readthedocs.io/en/stable/index.html)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "wb = Workbook()\n",
    "dest_filename = 'openpyxl_workbook.xlsx'\n",
    "ws1 = wb.active\n",
    "ws1.title = \"range names\"\n",
    "for row in range(1, 40):\n",
    "    ws1.append(range(600))\n",
    "ws2 = wb.create_sheet(title=\"Pi\")\n",
    "ws2['F5'] = 3.14\n",
    "ws3 = wb.create_sheet(title=\"Data\")\n",
    "for row in range(10, 20):\n",
    "    for col in range(27, 54):\n",
    "        _ = ws3.cell(column=col, row=row, value=\"{0}\".format(get_column_letter(col)))\n",
    "wb.save(filename = dest_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "wb = load_workbook(filename = 'openpyxl_workbook.xlsx')\n",
    "sheet_ranges = wb['range names']\n",
    "print(sheet_ranges['D18'].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IO operations using database systems  \n",
    "\n",
    "> Install [PostgreSQL](https://www.postgresql.org/download/) database and create 'testing user'. We will follow [this installation guide](https://www.postgresql.org/download/linux/ubuntu/) to install on ubuntu 18.04\n",
    "\n",
    "- Create the file **/etc/apt/sources.list.d/pgdg.list**  \n",
    "`$ sudo nano /etc/apt/sources.list.d/pgdg.list`  \n",
    "- add a line for the repository  \n",
    "`deb http://apt.postgresql.org/pub/repos/apt/ bionic-pgdg main`  \n",
    "- Exit editor with Ctrl+X, save edits.\n",
    "- Import the repository signing key, and update the package lists   \n",
    "`$ wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -`    \n",
    "`$ sudo apt-get update`   \n",
    "- Install postgresql database server   \n",
    "`$ sudo apt-get install postgresql`   \n",
    "- Login to database server as postgres user, create user nlpdemo and create database nlpcrash owned by user nlpdemo  \n",
    "`$ sudo su postgres`  \n",
    "`$ psql`  \n",
    "`> create role nlpdemo with login password 'UserPassword';`  \n",
    "`> create database nlpcrash owner nlpdemo;`\n",
    "`>\\q`  \n",
    "`$ exit`  \n",
    "\n",
    "\n",
    "\n",
    "We will use [psycopg2](http://initd.org/psycopg/docs/index.html) to connect to our database server. Psycopg2 is the most popular PostgreSQL database adapter for the Python programming language.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 100, \"abc'def\"), (2, 100, \"abc'def\"), (3, 100, \"abc'def\")]\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "db_conf={\n",
    "    \"user\":\"nlpdemo\",\n",
    "    \"password\":\"UserPassword\",\n",
    "    \"host\":\"localhost\",\n",
    "    \"port\":5432,\n",
    "    \"database\":\"nlpcrash\"\n",
    "}\n",
    "\n",
    "# Connect to an existing database\n",
    "conn = psycopg2.connect(\"dbname={} user={} host={} port={} password={}\".format(\n",
    "    db_conf['database'],\n",
    "    db_conf['user'],\n",
    "    db_conf['host'],\n",
    "    db_conf['port'],\n",
    "    db_conf['password']\n",
    "))\n",
    "\n",
    "# Open a cursor to perform database operations\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute a command: this creates a new table\n",
    "cur.execute(\"CREATE TABLE test (id serial PRIMARY KEY, num integer, data varchar);\")\n",
    "\n",
    "# Pass data to fill a query placeholders and let Psycopg perform\n",
    "# the correct conversion (no more SQL injections!)\n",
    "cur.execute(\"INSERT INTO test (num, data) VALUES (%s, %s)\",(100, \"abc'def\"))\n",
    "\n",
    "# Query the database and obtain data as Python objects\n",
    "cur.execute(\"SELECT * FROM test;\")\n",
    "print(cur.fetchall())\n",
    "\n",
    "# Make the changes to the database persistent\n",
    "conn.commit()\n",
    "\n",
    "# Close communication with the database\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Follow [this guide](http://initd.org/psycopg/docs/usage.html) that details advanced usage of psycopg2 package**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
